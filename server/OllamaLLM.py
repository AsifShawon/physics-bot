from langchain_community.llms import Ollama
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts import ChatPromptTemplate
from langchain.schema import SystemMessage, AIMessage, HumanMessage
from pdfToVectoreStore import search

# Initialize chat history and system message
chatHistory = []
systemMessage = """You are a helpful physics assistant, committed to delivering clear and accurate explanations. Always accompany your explanations with relevant examples, either from the provided physics book or generated by yourself.

For questions outside the domain of physics, respond with: I can assist only with physics-related queries.

You will be given additional context to guide your responses. Focus strictly on physics and avoid answering unrelated questions."""

chatHistory.append(SystemMessage(content=systemMessage))

# Initialize model once
ollama_model = Ollama(model="gemma2:2b-instruct-q5_K_M")

def generate_text(query):
    # Define different prompt templates
    general_prompt = """Question: {query}

Context: {context}

Please provide a clear and concise answer to the question, focusing on physics concepts. If possible, include a relevant example from the provided context or a well-known physics principle."""

    calculation_prompt = """Question: {query}

Context: {context}

This question requires a calculation. Please follow these steps:
1. Identify the relevant physics formula(s) needed to solve the problem.
2. List the given values and what needs to be calculated.
3. Show the step-by-step calculation process.
4. Provide the final answer with the correct units.
5. If possible, give a brief explanation of the result's significance in physics."""

    conceptual_prompt = """Question: {query}

Context: {context}

This question is about a physics concept. Please structure your response as follows:
1. Define the concept clearly.
2. Provide a real-world example or application of this concept.
3. If applicable, mention any related concepts or principles."""

    follow_up_prompt = """Follow-up Request: {query}

Based on the previous discussion, please address this follow-up request. If it's asking for:
- More details: Expand on the most relevant aspect of the previous explanation.
- An example: Provide a concrete example that illustrates the concept discussed.
- A description: Give a more detailed description of the topic, focusing on its key characteristics.
- Clarification: Identify any potential points of confusion in the previous explanation and clarify them.

Remember to maintain focus on physics concepts and their applications."""

    # Check if it's a follow-up question
    follow_up_keywords = ['tell me more', 'describe', 'give an example','give a example', 'explain further', 'clarify']
    is_follow_up = any(keyword in query.lower() for keyword in follow_up_keywords)

    if is_follow_up:
        selected_prompt = follow_up_prompt
        context = "This is a follow-up to the previous discussion. No new context is provided."
    else:
        # Retrieve context from physics documents for new questions
        retrieved_text = search(query)

        # Determine which prompt to use based on the query
        if any(keyword in query.lower() for keyword in ['calculate', 'solve', 'find the value']):
            selected_prompt = calculation_prompt
        elif any(keyword in query.lower() for keyword in ['what is', 'define', 'explain']):
            selected_prompt = conceptual_prompt
        else:
            selected_prompt = general_prompt

        # Check if relevant content was found
        if retrieved_text != "No relevant docs were retrieved using the relevance score threshold 0.5":
            context = f"Here are some documents that might help answer the question: \n{retrieved_text}"
        else:
            context = "Unfortunately, I couldn't find any relevant documents. I'll answer based on my general knowledge of physics."

    # Create the full prompt
    full_prompt = selected_prompt.format(query=query, context=context)

    # Add context to chat history
    chatHistory.append(HumanMessage(content=full_prompt))

    # Create prompt using chat history
    prompt = ChatPromptTemplate.from_messages(chatHistory)
    
    # Create output parser
    parser = StrOutputParser()

    # Chain prompt, model, and parser
    try:
        chain = prompt | ollama_model | parser
        response = chain.invoke({})
    except Exception as e:
        return f"Error generating response: {e}"

    # Add AI response to chat history
    chatHistory.append(AIMessage(content=response))

    return response

# To clear chat history for a new session
def clear_chat_history():
    chatHistory.clear()
    chatHistory.append(SystemMessage(content=systemMessage))